{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to CUDA Python with Numba\n",
    "\n",
    "The **[CUDA](https://en.wikipedia.org/wiki/CUDA)** compute platform enables remarkable application acceleration by enabling developers to execute code in a massively parallel fashion on NVIDA GPUs.\n",
    "\n",
    "**[Numba](http://numba.pydata.org/)** is a just-in-time Python function compiler that exposes a simple interface for accelerating numerically-focused Python functions. Numba is a very attractive option for Python programmers wishing to GPU accelerate their applications without needing to write C/C++ code, especially for developers already performing computationally heavy operations on NumPy arrays. Numba can be used to accelerate Python functions for the CPU, as well as for NVIDIA GPUs. **The focus of this course is the fundamental techniques needed to GPU-accelerate Python applications using Numba.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Structure\n",
    "\n",
    "This course is divided into **three** main sections:\n",
    "\n",
    "- _Introduction to CUDA Python with Numba_\n",
    "- _Custom CUDA Kernels in Python with Numba_\n",
    "- _Multidimensional Grids and Shared Memory for CUDA Python with Numba_\n",
    "\n",
    "Each section contains a final assessment problem, the successful completion of which will enable you to earn a Certificate of Competency for the course. Each section also contains an appendix with advanced materials for those of you with interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to CUDA Python with Numba\n",
    "\n",
    "In this first section you will learn first how to use Numba to compile functions for the CPU, and will receive an introduction to the inner workings of the Numba compiler. You will then proceed to learn how to GPU accelerate element-wise NumPy array functions, along with some techniques for efficiently moving data between a CPU host and GPU device.\n",
    "\n",
    "By the end of the first session you will be able to GPU accelerate Python code that performs element-wise operations on NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CUDA Kernels in Python with Numba\n",
    "\n",
    "In the second section you will expand your abilities to be able to launch arbitrary, not just element-wise, numerically focused functions in parallel on the GPU by writing custom CUDA kernels. In service of this goal you will learn about how NVIDIA GPUs execute code in parallel. Additionally, you will be exposed to several fundamental parallel programming techniques including how to coordinate the work of parallel threads, and how to address race conditions. You will also learn techniques for debugging code that executes on the GPU.\n",
    "\n",
    "By the end of the second section you will be ready to GPU accelerate an incredible range of numerically focused functions on 1D data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional Grids and Shared Memory for CUDA Python with Numba\n",
    "\n",
    "In the third section you will begin working in parallel with 2D data, and will learn how to utilize an on-chip memory space on the GPU called shared memory.\n",
    "\n",
    "By the end of the third section, you will be able to write GPU accelerated code in Python using Numba on 1D and 2D datasets while utilizing several of the most important optimization strategies for writing consistently fast GPU accelerated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Prerequisites\n",
    "\n",
    "* Competency writing Python, specifically, writing and invoking functions, working with variables, loops, and conditionals, and imports.\n",
    "* Familiarity with the NumPy Python library for numerically-focused Python. If you have never used NumPy, but are familiar with Python, you will likely find the use of NumPy in this session straightforward. Comments and links are provided where some clarification might be helpful.\n",
    "* A high level understanding of some computer science terms like memory allocation, value types, latency, and processing cores.\n",
    "* A basic understanding of what vectors and matrices are, and also matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives for this Section\n",
    "\n",
    "By the time you complete this section you will be able to:\n",
    "\n",
    "- Use Numba to compile Python functions for the CPU.\n",
    "- Understand how Numba compiles Python functions.\n",
    "- GPU accelerate NumPy ufuncs.\n",
    "- GPU accelerate hand-written vectorized functions.\n",
    "- Optimize data transfers between the CPU host and GPU device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Numba?\n",
    "\n",
    "Numba is a **just-in-time**, **type-specializing**, **function compiler** for accelerating **numerically-focused** Python for either a CPU or GPU. That's a long list, so let's break down those terms:\n",
    "\n",
    " * **function compiler**: Numba compiles Python functions, not entire applications, and not parts of functions.  Numba does not replace your Python interpreter, but is just another Python module that can turn a function into a (usually) faster function. \n",
    " * **type-specializing**: Numba speeds up your function by generating a specialized implementation for the specific data types you are using.  Python functions are designed to operate on generic data types, which makes them very flexible, but also very slow.  In practice, you only will call a function with a small number of argument types, so Numba will generate a fast implementation for each set of types.\n",
    " * **just-in-time**: Numba translates functions when they are first called.  This ensures the compiler knows what argument types you will be using.  This also allows Numba to be used interactively in a Jupyter notebook just as easily as a traditional application.\n",
    " * **numerically-focused**: Currently, Numba is focused on numerical data types, like `int`, `float`, and `complex`.  There is very limited string processing support, and many string use cases are not going to work well on the GPU.  To get best results with Numba, you will likely be using NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for Using Numba\n",
    "\n",
    "Numba supports a wide range of operating systems:\n",
    "\n",
    " * Windows 7 and later, 32 and 64-bit\n",
    " * macOS 10.9 and later, 64-bit\n",
    " * Linux (most anything >= RHEL 5), 32-bit and 64-bit\n",
    "\n",
    "and Python versions:\n",
    "\n",
    " * Python 2.7, 3.4-3.6\n",
    " * NumPy 1.10 and later\n",
    "\n",
    "and a very wide range of hardware:\n",
    "\n",
    "* x86, x86_64/AMD64 CPUs\n",
    "* NVIDIA CUDA GPUs (Compute capability 3.0 and later, CUDA 8.0 and later)\n",
    "* AMD GPUs (experimental patches)\n",
    "* ARM (experimental patches)\n",
    "\n",
    "For this course, we will be using Linux 64-bit and CUDA 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: CUDA C/C++ vs. Numba vs. pyCUDA\n",
    "\n",
    "By no means is Numba the only way to program with CUDA. By far the most common way to program in CUDA is with the CUDA C/C++ language extensions. With regards to Python, [pyCUDA](https://documen.tician.de/pycuda/) is, in addition to Numba, an alternative to GPU accelerating Python code. We will remained focused on Numba throughout this course, but a quick comparison of the three options just named is worth a mention before we get started, just for a little context.\n",
    "\n",
    "**CUDA C/C++**:\n",
    "- The most common, performant, and flexible way to utilize CUDA\n",
    "- Accelerates C/C++ applications\n",
    "\n",
    "**pyCUDA**:\n",
    "- Exposes the entire CUDA C/C++ API\n",
    "- Is the most performant CUDA option available for Python\n",
    "- Requires writing C code in your Python, and in general, a lot of code modifications\n",
    "\n",
    "**Numba**:\n",
    "- Potentially less performant than pyCUDA\n",
    "- Does not (yet?) expose the entire CUDA C/C++ API\n",
    "- Still enables massive acceleration, often with very little code modification\n",
    "- Allows developers the convenience of writing code directly in Python\n",
    "- Also optimizes Python code for the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Steps: Compile for the CPU\n",
    "\n",
    "If you recall Numba can be used to optimize code for either a CPU or GPU. As an introduction, and before moving onto GPU acceleration, let's write our first Numba function and compile it for the **CPU**. In doing so we will get an easy entrance into Numba syntax, and will also have an opportunity a little later on to compare the performance of CPU optimized Numba code to GPU acclerated Numba code.\n",
    "\n",
    "The Numba compiler is typically enabled by applying a [**function decorator**](https://en.wikipedia.org/wiki/Python_syntax_and_semantics#Decorators) to a Python function. Decorators are function modifiers that transform the Python functions they decorate, using a very simple syntax. Here we will use Numba's CPU compilation decorator `@jit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import math\n",
    "\n",
    "# This is the function decorator syntax and is equivalent to `hypot = jit(hypot)`.\n",
    "# The Numba compiler is just a function you can call whenever you want!\n",
    "@jit\n",
    "def hypot(x, y):\n",
    "    # Implementation from https://en.wikipedia.org/wiki/Hypot\n",
    "    x = abs(x);\n",
    "    y = abs(y);\n",
    "    t = min(x, y);\n",
    "    x = max(x, y);\n",
    "    t = t / x;\n",
    "    return x * math.sqrt(1+t*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out our hypotenuse calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypot(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go in to more detail below about what happens when `hypot` is called, but for now know that the first time we call `hypot`, the compiler is triggered and compiles a machine code implementation of the function for float inputs. Numba also saves the original Python implementation of the function in the `.py_func` attribute, so we can call the original Python code to make sure we get the same answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypot.py_func(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking\n",
    "\n",
    "An important part of using Numba is measuring the performance of your new code.  Let's see if we actually sped anything up.  The easiest way to do this in a Jupyter notebook, like the one this session is run in, is to use the [`%timeit` magic function](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit).  Let's first measure the speed of the original Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787 ns ± 8.24 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hypot.py_func(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%timeit` magic runs the statement many times to get an accurate estimate of the run time.  It also returns the best time by default, which is useful to reduce the probability that random background events affect your measurement.  The best of 3 approach also ensures that the compilation time on the first call doesn't skew the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 ns ± 0.0762 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hypot(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba did a pretty good job with this function.  It's certainly faster than the pure Python version. Of course, the `hypot` function is already present in the Python module, let's see how it compares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 ns ± 0.0864 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit math.hypot(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's built-in is even faster than Numba! This is because Numba does introduce some overhead to each function call that is larger than the function call overhead of Python itself. Extremely fast functions (like the above one) will be hurt by this. (As an aside, if you call one Numba function from another one, there is very little function overhead, sometimes even zero if the compiler inlines the function into the other one. In short, always benchmark your functions for evidence of speed up.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Use Numba to Compile a Function for the CPU\n",
    "\n",
    "The following function uses [the Monte Carlo Method to determine Pi](https://academo.org/demos/estimating-pi-monte-carlo/) (source code from the [Numba homepage](http://numba.pydata.org/)). The function itself is already working so don't worry about the mathematical implementation details.\n",
    "\n",
    "Complete the two `TODO`s in order to compile `monte_carlo_pi` with Numba before executing the following 3 cells which will:\n",
    "\n",
    "  1. Confirm the compiled version is behaving the same as the uncompiled version.\n",
    "  2. Benchmark the uncompiled version.\n",
    "  3. Benchmark the compiled version.\n",
    "\n",
    "If you get stuck, check out [the solution](../../../../edit/tasks/task1/task/solutions/monte_carlo_pi_solution.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nsamples = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Import Numba's just-in-time compiler function\n",
    "import random\n",
    "from numba import jit\n",
    "\n",
    "# TODO: Use the Numba compiler to compile this function\n",
    "@jit\n",
    "def monte_carlo_pi(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use numpy's `testing` library to confirm compiled and uncompiled versions run the same\n",
    "from numpy import testing\n",
    "\n",
    "# This assertion will fail until you successfully complete the exercise one cell above\n",
    "testing.assert_almost_equal(monte_carlo_pi(nsamples), monte_carlo_pi.py_func(nsamples), decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.5 ms ± 1.89 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit monte_carlo_pi(nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 ms ± 135 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit monte_carlo_pi.py_func(nsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Numba Works\n",
    "\n",
    "Now that you've gotton your hands a little dirty using the Numba compiler, let's take a look at what is actually going on under the hood. The first time we called our Numba-wrapped `hypot` function, the following process was initiated:\n",
    "\n",
    "![Numba Flowchart](images/numba_flowchart.png \"The compilation process\")\n",
    "\n",
    "We can see the result of type inference by using the `.inspect_types()` method, which prints an annotated version of the source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypot (float64, float64)\n",
      "--------------------------------------------------------------------------------\n",
      "# File: <ipython-input-30-1ae6c289554e>\n",
      "# --- LINE 6 --- \n",
      "# label 0\n",
      "#   del x\n",
      "#   del $0.1\n",
      "#   del $0.3\n",
      "#   del y\n",
      "#   del $0.4\n",
      "#   del $0.6\n",
      "#   del $0.7\n",
      "#   del $0.10\n",
      "#   del y.1\n",
      "#   del x.1\n",
      "#   del $0.11\n",
      "#   del $0.14\n",
      "#   del t\n",
      "#   del $0.17\n",
      "#   del $0.19\n",
      "#   del t.1\n",
      "#   del $const0.21\n",
      "#   del $0.24\n",
      "#   del $0.25\n",
      "#   del $0.20\n",
      "#   del x.2\n",
      "#   del $0.26\n",
      "#   del $0.27\n",
      "\n",
      "@jit\n",
      "\n",
      "# --- LINE 7 --- \n",
      "\n",
      "def hypot(x, y):\n",
      "\n",
      "    # --- LINE 8 --- \n",
      "\n",
      "    # Implementation from https://en.wikipedia.org/wiki/Hypot\n",
      "\n",
      "    # --- LINE 9 --- \n",
      "    #   x = arg(0, name=x)  :: float64\n",
      "    #   y = arg(1, name=y)  :: float64\n",
      "    #   $0.1 = global(abs: <built-in function abs>)  :: Function(<built-in function abs>)\n",
      "    #   $0.3 = call $0.1(x, func=$0.1, args=[Var(x, <ipython-input-30-1ae6c289554e> (9))], kws=(), vararg=None)  :: (float64,) -> float64\n",
      "    #   x.1 = $0.3  :: float64\n",
      "\n",
      "    x = abs(x);\n",
      "\n",
      "    # --- LINE 10 --- \n",
      "    #   $0.4 = global(abs: <built-in function abs>)  :: Function(<built-in function abs>)\n",
      "    #   $0.6 = call $0.4(y, func=$0.4, args=[Var(y, <ipython-input-30-1ae6c289554e> (9))], kws=(), vararg=None)  :: (float64,) -> float64\n",
      "    #   y.1 = $0.6  :: float64\n",
      "\n",
      "    y = abs(y);\n",
      "\n",
      "    # --- LINE 11 --- \n",
      "    #   $0.7 = global(min: <built-in function min>)  :: Function(<built-in function min>)\n",
      "    #   $0.10 = call $0.7(x.1, y.1, func=$0.7, args=[Var(x.1, <ipython-input-30-1ae6c289554e> (9)), Var(y.1, <ipython-input-30-1ae6c289554e> (10))], kws=(), vararg=None)  :: (float64, float64) -> float64\n",
      "    #   t = $0.10  :: float64\n",
      "\n",
      "    t = min(x, y);\n",
      "\n",
      "    # --- LINE 12 --- \n",
      "    #   $0.11 = global(max: <built-in function max>)  :: Function(<built-in function max>)\n",
      "    #   $0.14 = call $0.11(x.1, y.1, func=$0.11, args=[Var(x.1, <ipython-input-30-1ae6c289554e> (9)), Var(y.1, <ipython-input-30-1ae6c289554e> (10))], kws=(), vararg=None)  :: (float64, float64) -> float64\n",
      "    #   x.2 = $0.14  :: float64\n",
      "\n",
      "    x = max(x, y);\n",
      "\n",
      "    # --- LINE 13 --- \n",
      "    #   $0.17 = t / x.2  :: float64\n",
      "    #   t.1 = $0.17  :: float64\n",
      "\n",
      "    t = t / x;\n",
      "\n",
      "    # --- LINE 14 --- \n",
      "    #   $0.19 = global(math: <module 'math' from '/home/appuser/Miniconda3/lib/python3.6/lib-dynload/math.cpython-36m-x86_64-linux-gnu.so'>)  :: Module(<module 'math' from '/home/appuser/Miniconda3/lib/python3.6/lib-dynload/math.cpython-36m-x86_64-linux-gnu.so'>)\n",
      "    #   $0.20 = getattr(value=$0.19, attr=sqrt)  :: Function(<built-in function sqrt>)\n",
      "    #   $const0.21 = const(int, 1)  :: int64\n",
      "    #   $0.24 = t.1 * t.1  :: float64\n",
      "    #   $0.25 = $const0.21 + $0.24  :: float64\n",
      "    #   $0.26 = call $0.20($0.25, func=$0.20, args=[Var($0.25, <ipython-input-30-1ae6c289554e> (14))], kws=(), vararg=None)  :: (float64,) -> float64\n",
      "    #   $0.27 = x.2 * $0.26  :: float64\n",
      "    #   $0.28 = cast(value=$0.27)  :: float64\n",
      "    #   return $0.28\n",
      "\n",
      "    return x * math.sqrt(1+t*t)\n",
      "\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "hypot.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Numba's type names tend to mirror [the NumPy type names](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html), so a Python `float` is a `float64` (also called \"double precision\" in other languages).  Taking a look at the data types can sometimes be important in GPU code because the performance of `float32` and `float64` computations will be very different on CUDA devices. If your algorithm can obtain correct results using `float32`, then you should probably use that data type, because casting to `float64` can dramatically slow down the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object and nopython Modes\n",
    "\n",
    "Numba cannot compile all Python code.  Some functions don't have a Numba-translation, and some kinds of Python types can't be efficiently compiled at all (yet).  For example, Numba does not support dictionaries (as of this writing). Here let's try to compile some Python code that Numba does not yet know how to compile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'value'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def cannot_compile(x):\n",
    "    return x['key']\n",
    "\n",
    "cannot_compile(dict(key='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given what we just said, you might be surpised that the cell above executed without any problems. This is because by default, Numba will fall back to a mode, called **object mode**, which does not do type-specialization. Object mode exists to enable other Numba functionality, but in many cases, you want Numba to tell you if type inference fails. You can force **nopython mode** (the other compilation mode) by passing the `nopython` argument to the decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed at nopython (nopython frontend)\nInternal error at <numba.typeinfer.ArgConstraint object at 0x7f98d010ecf8>:\n--%<-----------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 259, in new_error_context\n    yield\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 189, in __call__\n    assert ty.is_precise()\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 137, in propagate\n    constraint(typeinfer)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 190, in __call__\n    typeinfer.add_type(self.dst, ty, loc=self.loc)\n  File \"/home/appuser/Miniconda3/lib/python3.6/contextlib.py\", line 99, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 265, in new_error_context\n    six.reraise(type(newerr), newerr, sys.exc_info()[2])\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/six.py\", line 658, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 259, in new_error_context\n    yield\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 189, in __call__\n    assert ty.is_precise()\nnumba.errors.InternalError: \n[1] During: typing of argument at <ipython-input-43-d3b98ca43e8a> (3)\n--%<-----------------------------------------------------------------\n\nFile \"<ipython-input-43-d3b98ca43e8a>\", line 3\n\nThis error may have been caused by the following argument(s):\n- argument 0: cannot determine Numba type of <class 'dict'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d3b98ca43e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcannot_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    328\u001b[0m                                 for i, err in failed_args))\n\u001b[1;32m    329\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minspect_llvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0margtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;31m# Intercept typing error that may be due to an argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_misses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_overload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_overload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                       \u001b[0mimpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                       flags=flags, locals=self.locals)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Check typing error if object mode is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pyobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library)\u001b[0m\n\u001b[1;32m    777\u001b[0m     pipeline = Pipeline(typingctx, targetctx, library,\n\u001b[1;32m    778\u001b[0m                         args, return_type, flags, locals)\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \"\"\"\n\u001b[1;32m    737\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;31m# Early pipeline completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;31m# No more fallback pipelines?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_final_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpatched_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                     \u001b[0;31m# Go to next fallback pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                     \u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0m_EarlyPipelineCompletion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mstage_nopython_frontend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 self.locals)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         with self.fallback_context('Function \"%s\" has invalid return type'\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mtype_inference_stage\u001b[0;34m(typingctx, interp, args, return_type, locals)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m         \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0mtypemap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalltypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, raise_errors)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed at nopython (nopython frontend)\nInternal error at <numba.typeinfer.ArgConstraint object at 0x7f98d010ecf8>:\n--%<-----------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 259, in new_error_context\n    yield\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 189, in __call__\n    assert ty.is_precise()\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 137, in propagate\n    constraint(typeinfer)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 190, in __call__\n    typeinfer.add_type(self.dst, ty, loc=self.loc)\n  File \"/home/appuser/Miniconda3/lib/python3.6/contextlib.py\", line 99, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 265, in new_error_context\n    six.reraise(type(newerr), newerr, sys.exc_info()[2])\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/six.py\", line 658, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 259, in new_error_context\n    yield\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 189, in __call__\n    assert ty.is_precise()\nnumba.errors.InternalError: \n[1] During: typing of argument at <ipython-input-43-d3b98ca43e8a> (3)\n--%<-----------------------------------------------------------------\n\nFile \"<ipython-input-43-d3b98ca43e8a>\", line 3\n\nThis error may have been caused by the following argument(s):\n- argument 0: cannot determine Numba type of <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "@jit(nopython=True)\n",
    "def cannot_compile(x):\n",
    "    return x['key']\n",
    "\n",
    "cannot_compile(dict(key='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get an exception when Numba tries to compile the function, and if you scroll down to the end of the exception output you will see an error that describes the underlying problem:\n",
    "```\n",
    "- argument 0: cannot determine Numba type of <class 'dict'>\n",
    "```\n",
    "\n",
    "**Using `nopython` mode is the recommended and best practice way to use `jit` as it leads to the best performance.**\n",
    "\n",
    "Numba provides another decorator `njit` which is an alias for `jit(nopython=True)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed at nopython (nopython frontend)\nInternal error at <numba.typeinfer.ArgConstraint object at 0x7f98d011d630>:\n--%<-----------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 259, in new_error_context\n    yield\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 189, in __call__\n    assert ty.is_precise()\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 137, in propagate\n    constraint(typeinfer)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 190, in __call__\n    typeinfer.add_type(self.dst, ty, loc=self.loc)\n  File \"/home/appuser/Miniconda3/lib/python3.6/contextlib.py\", line 99, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 265, in new_error_context\n    six.reraise(type(newerr), newerr, sys.exc_info()[2])\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/six.py\", line 658, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 259, in new_error_context\n    yield\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 189, in __call__\n    assert ty.is_precise()\nnumba.errors.InternalError: \n[1] During: typing of argument at <ipython-input-44-598d254e6e01> (5)\n--%<-----------------------------------------------------------------\n\nFile \"<ipython-input-44-598d254e6e01>\", line 5\n\nThis error may have been caused by the following argument(s):\n- argument 0: cannot determine Numba type of <class 'dict'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-598d254e6e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcannot_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    328\u001b[0m                                 for i, err in failed_args))\n\u001b[1;32m    329\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minspect_llvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0margtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;31m# Intercept typing error that may be due to an argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_misses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_overload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_overload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                       \u001b[0mimpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                       flags=flags, locals=self.locals)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Check typing error if object mode is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pyobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library)\u001b[0m\n\u001b[1;32m    777\u001b[0m     pipeline = Pipeline(typingctx, targetctx, library,\n\u001b[1;32m    778\u001b[0m                         args, return_type, flags, locals)\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \"\"\"\n\u001b[1;32m    737\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;31m# Early pipeline completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;31m# No more fallback pipelines?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_final_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpatched_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                     \u001b[0;31m# Go to next fallback pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                     \u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0m_EarlyPipelineCompletion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mstage_nopython_frontend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 self.locals)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         with self.fallback_context('Function \"%s\" has invalid return type'\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mtype_inference_stage\u001b[0;34m(typingctx, interp, args, return_type, locals)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m         \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0mtypemap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalltypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, raise_errors)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed at nopython (nopython frontend)\nInternal error at <numba.typeinfer.ArgConstraint object at 0x7f98d011d630>:\n--%<-----------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 259, in new_error_context\n    yield\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 189, in __call__\n    assert ty.is_precise()\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 137, in propagate\n    constraint(typeinfer)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 190, in __call__\n    typeinfer.add_type(self.dst, ty, loc=self.loc)\n  File \"/home/appuser/Miniconda3/lib/python3.6/contextlib.py\", line 99, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 265, in new_error_context\n    six.reraise(type(newerr), newerr, sys.exc_info()[2])\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/six.py\", line 658, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/errors.py\", line 259, in new_error_context\n    yield\n  File \"/home/appuser/Miniconda3/lib/python3.6/site-packages/numba/typeinfer.py\", line 189, in __call__\n    assert ty.is_precise()\nnumba.errors.InternalError: \n[1] During: typing of argument at <ipython-input-44-598d254e6e01> (5)\n--%<-----------------------------------------------------------------\n\nFile \"<ipython-input-44-598d254e6e01>\", line 5\n\nThis error may have been caused by the following argument(s):\n- argument 0: cannot determine Numba type of <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def cannot_compile(x):\n",
    "    return x['key']\n",
    "\n",
    "cannot_compile(dict(key='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to [the Numba documentation](https://numba.pydata.org/numba-doc/dev/reference/pysupported.html) for an exhaustive account of Numba-supported Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Numba for the GPU with NumPy Universal Functions (ufuncs)\n",
    "\n",
    "We will begin our coverage of GPU programming in Numba with how to compile [NumPy Universal functions \\(or ufuncs\\)](https://docs.scipy.org/doc/numpy-1.15.1/reference/ufuncs.html) for the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing to know about GPU programming as we get started is that GPU hardware is designed for *data parallelism*. Maximum throughput is achieved when the GPU is computing the same operations on many different elements at once.\n",
    "\n",
    "NumPy Universal functions, which perform the same operation on every element in a NumPy array, are naturally data parallel, so they are a natural fit for GPU programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of NumPy Universal Functions (ufuncs)\n",
    "\n",
    "Familiarity with NumPy ufuncs is a prerequisite of this course, but in case you are unfamiliar with them, or in case it has been a while, here is a very brief introduction. If, at the end of this brief introduction, you don't feel comfortable with the basic NumPy mechanisms for array creation and ufuncs, consider the ~1 hour [NumPy Quickstart Tutorial](https://docs.scipy.org/doc/numpy/user/quickstart.html).\n",
    "\n",
    "NumPy has the concept of universal functions (\"ufuncs\"), which are functions that can take NumPy arrays of varying dimensions, or scalars, and operate on them element-by-element.\n",
    "\n",
    "As an example we'll use the NumPy `add` ufunc to demonstrate the basic ufunc mechanism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 22, 33, 44])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([10, 20, 30, 40])\n",
    "\n",
    "np.add(a, b) # Returns a new NumPy array resulting from adding every element in `a` to every element in `b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ufuncs also can combine scalars with arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101, 102, 103, 104])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(a, 100) # Returns a new NumPy array resulting from adding 100 to every element in `a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays of different, but compatible dimensions can also be combined via a technique called [*broadcasting*](https://docs.scipy.org/doc/numpy-1.15.0/user/basics.broadcasting.html). The lower dimensional array will be replicated to match the dimensionality of the higher dimensional array. If needed, check out the docs for [`numpy.arange`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.arange.html) and [`numpy.ndarray.reshape`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.ndarray.reshape.html), both will be used several times throughout this course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10, 21, 32, 43],\n",
       "       [14, 25, 36, 47],\n",
       "       [18, 29, 40, 51],\n",
       "       [22, 33, 44, 55]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.arange(4*4).reshape((4,4))\n",
    "print('c:', c)\n",
    "\n",
    "np.add(b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making ufuncs for the GPU\n",
    "\n",
    "Numba has the ability to create *compiled* ufuncs, typically a not-so-straighforward process involving C code. With Numba you simply implement a scalar function to be performed on all the inputs, decorate it with `@vectorize`, and Numba will figure out the broadcast rules for you. For those of you familiar with [NumPy's `vectorize`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.vectorize.html), Numba's `vectorize` decorator will be very familiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this very first example we will use the `@vectorize` decorator to compile and optimize a ufunc for the **CPU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize\n",
    "def add_ten(num):\n",
    "    return num + 10 # This scalar operation will be performed on each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466 ns ± 3.44 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "nums = np.arange(10)\n",
    "%timeit add_ten(nums) # pass the whole array into the ufunc, it performs the operation on each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generating a ufunc that uses CUDA on the GPU with the addition of giving an **explicit type signature** and setting the `target` attribute. The type signature argument describes what types to use both for the ufuncs arguments and return value:\n",
    "```python\n",
    "'return_value_type(argument1_value_type, argument2_value_type, ...)'\n",
    "```\n",
    "\n",
    "Please see the Numba docs for more on [available types](https://numba.pydata.org/numba-doc/dev/reference/types.html), as well as for additional information on [writing ufuncs with more than one signature](https://numba.pydata.org/numba-doc/dev/user/vectorize.html)\n",
    "\n",
    "Here is a simple example of a ufunc that will be compiled for a CUDA enabled GPU device. It expects two `int64` values and return also an `int64` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['int64(int64, int64)'], target='cuda') # Type signature and target are required for the GPU\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 22, 33, 44])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_ufunc(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For such a simple function call, a lot of things just happened!  Numba just automatically:\n",
    "\n",
    " * Compiled a CUDA kernel to execute the ufunc operation in parallel over all the input elements.\n",
    " * Allocated GPU memory for the inputs and the output.\n",
    " * Copied the input data to the GPU.\n",
    " * Executed the CUDA kernel (GPU function) with the correct kernel dimensions given the input sizes.\n",
    " * Copied the result back from the GPU to the CPU.\n",
    " * Returned the result as a NumPy array on the host.\n",
    " \n",
    "Compared to an implementation in C, the above is remarkably more concise.\n",
    "\n",
    "You might be wondering how fast our simple example is on the GPU?  Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4 µs ± 5.02 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.add(b, c)   # NumPy on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866 µs ± 3.93 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(b, c) # Numba on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, the GPU is *a lot slower* than the CPU?? For the time being this is to be expected because we have (deliberately) misused the GPU in several ways in this example. How we have misused the GPU will help clarify what kinds of problems are well-suited for GPU computing, and which are best left to be performed on the CPU:\n",
    "\n",
    "  * **Our inputs are too small**: the GPU achieves performance through parallelism, operating on thousands of values at once.  Our test inputs have only 4 and 16 integers, respectively.  We need a much larger array to even keep the GPU busy.\n",
    "  * **Our calculation is too simple**: Sending a calculation to the GPU involves quite a bit of overhead compared to calling a function on the CPU.  If our calculation does not involve enough math operations (often called \"arithmetic intensity\"), then the GPU will spend most of its time waiting for data to move around.\n",
    "  * **We copy the data to and from the GPU**: While in some scenarios, paying the cost of copying data to and from the GPU can be worth it for a single function, often it will be preferred to to run several GPU operations in sequence. In those cases, it makes sense to send data to the GPU and keep it there until all of our processing is complete.\n",
    "  * **Our data types are larger than necessary**: Our example uses `int64` when we probably don't need it.  Scalar code using data types that are 32 and 64-bit run basically the same speed on the CPU, and for integer types the difference may not be drastic, but 64-bit floating point data types have a significant performance cost on the GPU.  Basic arithmetic on 64-bit floats can be anywhere from 2x (Pascal-architecture Tesla) to 24x (Maxwell-architecture GeForce) slower than 32-bit floats.  NumPy defaults to 64-bit data types when creating arrays, so it is important to set the [`dtype`](https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.dtypes.html) attribute or use the [`ndarray.astype()`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.ndarray.astype.html) method to pick 32-bit types when you need them.\n",
    "  \n",
    "  \n",
    "Given the above, let's try an example that is faster on the GPU by performing an operation with much greater arithmetic intensity, on a much larger input, and using a 32-bit data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math # Note that for the CUDA target, we need to use the scalar functions from the math module, not NumPy\n",
    "\n",
    "SQRT_2PI = np.float32((2*math.pi)**0.5)  # Precompute this constant as a float32.  Numba will inline it at compile time.\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2811236], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Evaluate the Gaussian a million times!\n",
    "x = np.random.uniform(-3, 3, size=1000000).astype(np.float32)\n",
    "mean = np.float32(0.0)\n",
    "sigma = np.float32(1.0)\n",
    "\n",
    "# Quick test on a single element just to make sure it works\n",
    "gaussian_pdf(x[0], 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 ms ± 405 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats # for definition of gaussian distribution, so we can compare CPU to GPU time\n",
    "norm_pdf = scipy.stats.norm\n",
    "%timeit norm_pdf.pdf(x, loc=mean, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6 ms ± 11.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty large improvement, even including the overhead of copying all the data to and from the GPU.  Ufuncs that use special functions (`exp`, `sin`, `cos`, etc) on large data sets run especially well on the GPU.\n",
    "\n",
    "To complete our comparison, let's define and time our `gaussian_pdf` function when optimized by Numba for the **CPU**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize\n",
    "def cpu_gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.2 ms ± 34.7 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cpu_gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much faster than the uncompiled CPU version, but much slower than the GPU accelerated one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Device Functions\n",
    "\n",
    "Ufuncs are really quite fantastic if and when you want to perform element wise operations, which is a very common task. There are any number of functions however, that do not fit this description. To compile functions for the GPU that are **not** element wise, vectorized functions, we use `numba.cuda.jit`. In the next section of this course we work extensively with `numba.cuda.jit`, but for now, let us demonstrate how to use it to decorate a helper function, to be utilized by a GPU accelerated ufunc, so that you are not required to cram all your logic into a single ufunc defintion.\n",
    "\n",
    "Notice that `polar_to_cartesian` below does not require a type signature, and also, that it is passed two scalar values, unlike the vectorized ufuncs we have been using (and like `polar_distance` below) which expect NumPy arrays as arguments.\n",
    "\n",
    "The argument `device=True` indicates that the decorated function can **only** be called from a function running on the GPU, and not from CPU host code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def polar_to_cartesian(rho, theta):\n",
    "    x = rho * math.cos(theta)\n",
    "    y = rho * math.sin(theta)\n",
    "    return x, y\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32, float32)'], target='cuda')\n",
    "def polar_distance(rho1, theta1, rho2, theta2):\n",
    "    x1, y1 = polar_to_cartesian(rho1, theta1) # We can use device functions inside our GPU ufuncs\n",
    "    x2, y2 = polar_to_cartesian(rho2, theta2)\n",
    "    \n",
    "    return ((x1 - x2)**2 + (y1 - y2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "rho1 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta1 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)\n",
    "rho2 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta2 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9785951 , 0.55262744, 2.2617075 , ..., 0.5321942 , 1.5038633 ,\n",
       "       0.67010313], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polar_distance(rho1, theta1, rho2, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the CUDA compiler aggressively inlines device functions, so there is generally no overhead for function calls.  Similarly, the \"tuple\" returned by `polar_to_cartesian` is not actually created as a Python object, but represented temporarily as a struct, which is then optimized away by the compiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allowed Python on the GPU\n",
    "\n",
    "Compared to Numba on the CPU (which is already limited), Numba on the GPU has more limitations.  Supported Python includes:\n",
    "\n",
    "* `if`/`elif`/`else`\n",
    "* `while` and `for` loops\n",
    "* Basic math operators\n",
    "* Selected functions from the `math` and `cmath` modules\n",
    "* Tuples\n",
    "\n",
    "See [the Numba manual](http://numba.pydata.org/numba-doc/latest/cuda/cudapysupported.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: GPU Accelerate a Function\n",
    "\n",
    "Let's GPU accelerate a \"zero suppression\" function. A common operation when working with waveforms is to force all sample values below a certain absolute magnitude to be zero, as a way to eliminate low amplitude noise. Let's make some sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98a8794358>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwzCSw0LPMAwjOf8Pz2Gi7aSARxcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f98a989ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This allows us to plot right here in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Hacking up a noisy pulse train\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "n = 100000\n",
    "noise = np.random.normal(size=n) * 3\n",
    "pulses = np.maximum(np.sin(np.arange(n) / (n / 23)) - 0.3, 0.0)\n",
    "waveform = ((pulses * 300) + noise).astype(np.int16)\n",
    "plt.plot(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now decorate this `zero_suppress` function to run as a vectorized ufunc on the CUDA device. Check out [the solution](../../../../edit/tasks/task1/task/solutions/zero_suppress_solution.py) if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize(['int16(int16,int16)'],target='cuda')\n",
    "def zero_suppress(waveform_value, threshold):\n",
    "    if waveform_value < threshold:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = waveform_value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98a860b320>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmOiJiCzHRE9EZDkmeiIiy/0PDmiJ8A7eglQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f98a8679128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This will throw an error until you successfully vectorize the `zero_suppress` function above.\n",
    "# The noise on the baseline should disappear when zero_suppress is implemented\n",
    "plt.plot(zero_suppress(waveform, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing GPU Memory\n",
    "\n",
    "So far we have used NumPy arrays on the CPU as inputs and outputs to our GPU functions. As a convenience, Numba has been automatically transferring this data to the GPU for us so that it can be operated on by the GPU. With this implicit data transfer Numba, acting conservatively, will automatically transfer the data back to the CPU after processing. As you can imagine, this is a very time intensive operation.\n",
    "\n",
    "The [CUDA Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html) indicates:\n",
    "\n",
    "> **High Priority**: Minimize data transfer between the host and the device, even if it means running some kernels on the device that do not show performance gains when compared with running them on the host CPU.\n",
    "\n",
    "With this in mind, we ought to consider how to prevent this automatic data transfer back to the host so that we can perform additional work on the data, only paying the price of copying it back to the host when we are truly ready.\n",
    "\n",
    "The way to do this is to create **CUDA Device Arrays** and pass them to our GPU functions. Device arrays will not be automatically transfered back to the host after processing, and can be reused as we wish on the device before ultimately, and only if necessary, sending them, or parts of them, back to the host.\n",
    "\n",
    "To demonstrate, let's create our example addition ufunc again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100000\n",
    "x = np.arange(n).astype(np.float32)\n",
    "y = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42 ms ± 1.28 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(x, y)  # Baseline performance with host arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `numba.cuda` module includes a function that will copy host data to the GPU and return a CUDA device array. Note that below when we try to print the content of the device array, we only get information about the array, and not its actual contents. This is because the data is on the device, and we would need to transfer it back to the host in order to print its values, which we will show how to do later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f98a86ea358>\n",
      "(100000,)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "x_device = cuda.to_device(x)\n",
    "y_device = cuda.to_device(y)\n",
    "\n",
    "print(x_device)\n",
    "print(x_device.shape)\n",
    "print(x_device.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device arrays can be passed to CUDA functions just like NumPy arrays, but without the copy overhead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598 µs ± 651 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(x_device, y_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `x_device` and `y_device` are already on the device, this benchmark is much faster.\n",
    "\n",
    "We are, however, still allocating a device array for the output of the ufunc and copying it back to the host, even though in the cell above we are not actually assigning the array to a variable. To avoid this, we can create the output array with the [`numba.cuda.device_array()`](https://numba.pydata.org/numba-doc/dev/cuda-reference/memory.html#numba.cuda.device_array) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_device = cuda.device_array(shape=(n,), dtype=np.float32)  # does not initialize the contents, like np.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And then we can use a special `out` keyword argument to the ufunc to specify the output buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 µs ± 738 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(x_device, y_device, out=out_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This call to `add_ufunc` does not involve any data transfers between the host and device and therefore runs the fastest. If and when we want to bring a device array back to the host memory, we can use the `copy_to_host()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
     ]
    }
   ],
   "source": [
    "out_host = out_device.copy_to_host()\n",
    "print(out_host[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be thinking that we are not comparing apples to apples here since we have not been benchmarking the `to_device` calls when using the device arrays although the implicit data transfers are being counted towards the benchmarking when we use host arrays `a` and `b`, and you would be correct. Of course our `add_func` function is not particularly well suited for the GPU as discussed earlier. The above was only intended to demonstrate how the transfers can be eliminated.\n",
    "\n",
    "Be sure to benchmark your data transfers when exploring whether or not a trip to the GPU is worth it.\n",
    "\n",
    "Also, Numba provides additional methods for managing device memory and data transfer, check out [the docs](https://numba.pydata.org/numba-doc/dev/cuda/memory.html) for full details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Optimize Memory Movement\n",
    "\n",
    "Given these ufuncs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from numba import cuda\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def make_pulses(i, period, amplitude):\n",
    "    return max(math.sin(i / period) - 0.3, 0.0) * amplitude\n",
    "\n",
    "n = 100000\n",
    "noise = (np.random.normal(size=n) * 3).astype(np.float32)\n",
    "t = np.arange(n, dtype=np.float32)\n",
    "period = n / 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it currently stands in the cell below, there is an unnecessary data roundtrip back to the host and then back again to the device in between the calls to `make_pulses` and `add_ufunc`.\n",
    "\n",
    "Update the cell below to use device allocations so that there is only one copy to device before the call to `make_pulses` and one copy back to host after the call to `add_ufunc`. Check out [the solution](../../../../edit/tasks/task1/task/solutions/make_pulses_solution.py) if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_t = cuda.to_device(t)\n",
    "d_noise = cuda.to_device(noise)\n",
    "\n",
    "d_pulses = cuda.device_array(shape=(n,),dtype=np.float32)\n",
    "\n",
    "make_pulses(d_t, period, 100.0, out=d_pulses)\n",
    "waveform = add_ufunc(d_pulses, d_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "noise = (np.random.normal(size=n) * 3).astype(np.float32)\n",
    "t = np.arange(n, dtype=np.float32)\n",
    "period = n / 23\n",
    "\n",
    "d_noise = cuda.to_device(noise)\n",
    "d_t = cuda.to_device(t)\n",
    "d_pulses = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "\n",
    "make_pulses(d_t, period, 100.0, out=d_pulses)\n",
    "waveform = add_ufunc(d_pulses, d_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98a854a908>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f98a8589ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment\n",
    "\n",
    "The following exercise will require you to utilize everything you've learned so far. Unlike previous exercises, there will not be any solution code available to you, and, there are a couple additional steps you will need to take to \"run the assessment\" and get a score for your attempt(s). **Please read the directions carefully before beginning your work to ensure the best chance at successfully completing the assessment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Run the Assessment\n",
    "\n",
    "Take the following steps to complete this assessment:\n",
    "\n",
    "1. Using the instructions that follow, work on the cells below as you usually would for an exercise.\n",
    "2. When you are satisfied with your work, follow the instructions below to copy and paste code into linked source code files. Be sure to save the files after you paste your work.\n",
    "3. Return to the browser tab you used to launch this notebook, and click on the **\"Assess\"** button. After a few seconds a score will be generated along with a helpful message.\n",
    "\n",
    "You are welcome to click on the **Assess** button as many times as you like, so feel free if you don't pass the first time to make additional modifications to your code and repeat steps 1 through 3. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerate Neural Network Calculations\n",
    "\n",
    "The following is a simple version of performing some work needed to create a hidden layer in a neural network. It normalizes a million grayscale values (simply created randomly here), weighs them, and applies an activation function.\n",
    "\n",
    "Your task is to move this work to the GPU using the techniques you've learned, retain the correctness of the calculations, and improve the performance of the function calls , which, according to the `timeit` magic, currently take about *50 ms*, to run instead under *5 ms*.\n",
    "\n",
    "Here are a couple reminders to consider before you begin your work:\n",
    "\n",
    "* Sending values to the device once, and leaving it there for multiple operations is a huge improvement over moving it between the host and device for every function call. In this lesson you learned how to use device arrays for output and reuse them on the GPU without a roundtrip back and from the host.\n",
    "* `np` math functions won't work on the device, you need to use their `math` counterparts instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not modify this cell, these are the values that you will be assessed against.\n",
    "n = 1000000\n",
    "\n",
    "greyscales = np.floor(np.random.uniform(0, 255, n).astype(np.float32))\n",
    "weights = np.random.normal(.5, .1, n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell immediately below is used to import libraries, define data structures, and define functions. After making any modifications, and before running the assessment, paste this cell's content into [**`assessment/definitions.py`**](../../../../edit/tasks/task1/task/assessment/definitions.py) and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that we can't use numpy math function on the GPU...\n",
    "from math import exp\n",
    "from numba import vectorize\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "# Consider modifying the 3 values in this cell to optimize host <-> device memory movement\n",
    "normalized = cuda.to_device(np.empty_like(greyscales,dtype=np.float32))\n",
    "weighted = cuda.to_device(np.empty_like(greyscales,dtype=np.float32))\n",
    "activated = cuda.to_device(np.empty_like(greyscales,dtype=np.float32))\n",
    "\n",
    "\n",
    "\n",
    "# Modify these 3 function calls to run on the GPU\n",
    "@vectorize(['float32(float32)'], target='cuda')\n",
    "def normalize(grayscales):\n",
    "    return grayscales / 255\n",
    "\n",
    "@vectorize(['float32(float32,float32)'], target='cuda')\n",
    "def weigh(values, weights):\n",
    "    return values * weights\n",
    "\n",
    "@vectorize(['float32(float32)'], target='cuda')        \n",
    "def activate(values):\n",
    "    return ( exp(values) - exp(-values) ) / ( exp(values) + exp(-values) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell immediately below is used to call functions, using the defintions and data from the cell above. Without any modification, `timeit` reports a runtime of about *50 ms*. Your job is to accelerate it, explicitly controlling data transfers so that the calls to the 3 functions are timed to run under *5 ms*.\n",
    "\n",
    "After making any modifications, and before running the assessment, paste this cell's content into [**`assessment/calls.py`**](../../../../edit/tasks/task1/task/assessment/calls.py) and save it. **Important: The assessment will check for an array by the name of `SOLUTION`, so no matter how you refactor the code, be sure that the final results are stored in an array by the name of `SOLUTION`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.62 ms ± 53.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Feel free to modify the 3 function calls in this cell\n",
    "normalize(greyscales, out= normalized)\n",
    "weigh(normalized, weights, out= weighted)\n",
    "activate(weighted, out=activated)\n",
    "SOLUTION = activated.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Now that you have completed this session you are able to:\n",
    "\n",
    "- Use Numba to compile Python functions for the CPU\n",
    "- Understand how Numba compiles functions\n",
    "- GPU accelerate NumPy ufuncs\n",
    "- GPU accelerate hand-written vectorized functions\n",
    "- Optimize memory transfers between the CPU host and GPU device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Content\n",
    "\n",
    "To download the contents of this notebook, execute the following cell and then click the download link below. Note: If you run this notebook on a local Jupyter server, you can expect some of the file path links in the notebook to be broken as they are shaped to our own platform. You can still navigate to the files through the Jupyter file navigator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\r\n",
      "./images/\r\n",
      "./images/DLI Header.png\r\n",
      "./images/numba_flowchart.png\r\n",
      "./assessment/\r\n",
      "./assessment/definitions.py\r\n",
      "./assessment/calls.py\r\n",
      "./solutions/\r\n",
      "./solutions/zero_suppress_solution.py\r\n",
      "./solutions/make_pulses_solution.py\r\n",
      "./solutions/monte_carlo_pi_solution.py\r\n",
      "./Introduction to CUDA Python with Numba.ipynb\r\n",
      "./.ipynb_checkpoints/\r\n",
      "./.ipynb_checkpoints/Introduction to CUDA Python with Numba-checkpoint.ipynb\r\n",
      "./.ipynb_checkpoints/Introduction to CUDA Python with Numba-Copy1-checkpoint.ipynb\r\n",
      "./Introduction to CUDA Python with Numba-Copy1.ipynb\r\n",
      "tar: .: file changed as we read it\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf section1.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Download files from this section.](files/section1.tar.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Generalized Ufuncs\n",
    "\n",
    "Ufuncs broadcast a scalar function over array inputs but what if you want to broadcast a lower dimensional array function over a higher dimensional array?  This is called a *generalized ufunc* (\"gufunc\"), and it opens up a whole new frontier for applying ufuncs.\n",
    "\n",
    "Generalized ufuncs are a little more tricky because they need a *signature* (not to be confused with the Numba type signature) that shows the index ordering when dealing with multiple inputs.  Fully explaining \"gufunc\" signatures is beyond the scope of this tutorial, but you can learn more from:\n",
    "\n",
    "* The NumPy docs on gufuncs: https://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html\n",
    "* The Numba docs on gufuncs: http://numba.pydata.org/numba-doc/latest/user/vectorize.html#the-guvectorize-decorator\n",
    "* The Numba docs on CUDA gufuncs: http://numba.pydata.org/numba-doc/latest/cuda/ufunc.html#generalized-cuda-ufuncs\n",
    "\n",
    "Let's write our own normalization function.  This will take an array input and compute the L2 norm along the last dimension.  Generalized ufuncs take their output array as the last argument, rather than returning a value. If the output is a scalar, then we will still receive an array that is one dimension less than the array input. For example, computing the row sums of an array will return a 1 dimensional array for 2D array input, or 2D array for 3D array input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import guvectorize\n",
    "import math\n",
    "\n",
    "@guvectorize(['(float32[:], float32[:])'], # have to include the output array in the type signature\n",
    "             '(i)->()',                 # map a 1D array to a scalar output\n",
    "             target='cuda')\n",
    "def l2_norm(vec, out):\n",
    "    acc = 0.0\n",
    "    for value in vec:\n",
    "        acc += value**2\n",
    "    out[0] = math.sqrt(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this, let's construct some points on the unit circle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99993299 -0.01157628]\n",
      " [-0.2967657   0.95495032]\n",
      " [-0.41250966 -0.91095322]\n",
      " [-0.43421701  0.9008083 ]\n",
      " [ 0.64265291  0.76615745]\n",
      " [ 0.98286852  0.1843081 ]\n",
      " [ 0.73549065  0.67753487]\n",
      " [-0.91982906  0.39231939]\n",
      " [-0.32913578 -0.94428261]\n",
      " [ 0.99886929 -0.04754091]]\n"
     ]
    }
   ],
   "source": [
    "angles = np.random.uniform(-np.pi, np.pi, 10)\n",
    "coords = np.stack([np.cos(angles), np.sin(angles)], axis=1)\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the L2 norm is 1.0, up to rounding errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603 µs ± 3.78 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "l2_norm(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
